import streamlit as st
import os
import time
import shutil
import gc
import sys
import chromadb
from src.ingestion import ingest_document
from src.rag_chain import get_rag_chain, log_feedback
import config
from langchain_core.messages import AIMessage, HumanMessage

# --- 1. æ ¸å¿ƒçŠ¶æ€åˆå§‹åŒ– ---
if "has_cleared" not in st.session_state:
    st.session_state["has_cleared"] = False

if "uploader_key" not in st.session_state:
    st.session_state["uploader_key"] = 0

# --- 2. å‘½ä»¤è¡Œå‚æ•°å¤„ç† ---
if "--clear" in sys.argv and not st.session_state["has_cleared"]:
    st.session_state["has_cleared"] = True
    print("æ£€æµ‹åˆ° --clear å‚æ•°ï¼Œå°è¯•æ¸…ç†æ•°æ®...")

    # ç‰©ç†æ¸…ç† data
    if os.path.exists("data"):
        try:
            shutil.rmtree("data")
            print("å·²åˆ é™¤: data æ–‡ä»¶å¤¹")
        except Exception as e:
            print(f"åˆ é™¤ data å¤±è´¥: {e}")

    # ç‰©ç†æ¸…ç† æ•°æ®åº“
    if os.path.exists(config.PERSIST_DIRECTORY):
        try:
            shutil.rmtree(config.PERSIST_DIRECTORY, ignore_errors=True)
            print(f"å·²æ¸…ç†æ•°æ®åº“: {config.PERSIST_DIRECTORY}")
        except Exception as e:
            print(f"åˆ é™¤æ•°æ®åº“å¤±è´¥: {e}")

    # ç‰©ç†æ¸…ç† çˆ¶æ–‡æ¡£å­˜å‚¨ (DocStore)
    doc_store_path = getattr(config, "PARENT_DOC_STORE_PATH", "doc_store")
    if os.path.exists(doc_store_path):
        try:
            shutil.rmtree(doc_store_path, ignore_errors=True)
            print(f"å·²æ¸…ç†çˆ¶æ–‡æ¡£å­˜å‚¨: {doc_store_path}")
        except Exception as e:
            print(f"åˆ é™¤çˆ¶æ–‡æ¡£å­˜å‚¨å¤±è´¥: {e}")

    # ç‰©ç†æ¸…ç† æå–çš„å›¾ç‰‡å­˜å‚¨
    img_store_path = getattr(config, "IMG_STORE_PATH", "extracted_images")
    if os.path.exists(img_store_path):
        try:
            shutil.rmtree(img_store_path, ignore_errors=True)
            print(f"å·²æ¸…ç†æå–å›¾ç‰‡å­˜å‚¨: {img_store_path}")
        except Exception as e:
            print(f"åˆ é™¤æå–å›¾ç‰‡å­˜å‚¨å¤±è´¥: {e}")


# --- 3. é‡ç½®å‡½æ•°å®šä¹‰ ---
def reset_app():
    """
    é‡ç½®åº”ç”¨ï¼šé€»è¾‘æ¸…ç©ºæ•°æ®åº“ -> æ¸…ç†ç¼“å­˜ -> åˆ é™¤åŸå§‹æ–‡ä»¶ -> åˆ é™¤ä¸­é—´äº§ç‰©
    """
    print("æ‰§è¡Œé‡ç½®ä¸­...")

    # 1. é€»è¾‘æ¸…ç©ºå‘é‡æ•°æ®åº“ (API æ–¹å¼)
    if os.path.exists(config.PERSIST_DIRECTORY):
        try:
            print("æ­£åœ¨é€šè¿‡ API æ¸…ç©ºå‘é‡åº“...")
            client = chromadb.PersistentClient(path=config.PERSIST_DIRECTORY)
            try:
                client.delete_collection("langchain")
                print("âœ… å·²åˆ é™¤ 'langchain' é›†åˆ")
            except ValueError:
                print("é›†åˆä¸å­˜åœ¨ï¼Œæ— éœ€åˆ é™¤")
            except Exception as e:
                print(f"åˆ é™¤é›†åˆæ—¶å‡ºé”™: {e}")
        except Exception as e:
            print(f"è¿æ¥æ•°æ®åº“å¤±è´¥: {e}")

    # 2. ç‰©ç†åˆ é™¤ BM25 ç´¢å¼•
    if os.path.exists(config.BM25_PERSIST_PATH):
        try:
            os.remove(config.BM25_PERSIST_PATH)
            print("å·²åˆ é™¤ BM25 ç´¢å¼•æ–‡ä»¶")
        except Exception as e:
            print(f"åˆ é™¤ BM25 å¤±è´¥: {e}")

    # 3. ç‰©ç†åˆ é™¤ SQLite çˆ¶æ–‡æ¡£å­˜å‚¨
    sqlite_path = getattr(config, "SQLITE_DB_PATH", "./doc_store.db")
    if os.path.exists(sqlite_path):
        try:
            os.remove(sqlite_path)
            print(f"å·²åˆ é™¤ SQLite æ•°æ®åº“: {sqlite_path}")
        except Exception as e:
            print(f"åˆ é™¤ SQLite æ•°æ®åº“å¤±è´¥: {e}")

    # 4. ç‰©ç†åˆ é™¤æ—§çš„ pkl çˆ¶æ–‡æ¡£å­˜å‚¨ (å‘åå…¼å®¹)
    doc_store_path = getattr(config, "PARENT_DOC_STORE_PATH", "doc_store")
    if os.path.exists(doc_store_path):
        try:
            shutil.rmtree(doc_store_path)
            print(f"å·²åˆ é™¤æ—§çˆ¶æ–‡æ¡£å­˜å‚¨: {doc_store_path}")
        except Exception as e:
            st.error(f"æ— æ³•åˆ é™¤çˆ¶æ–‡æ¡£å­˜å‚¨ {doc_store_path}: {e}")

    # 4. ç‰©ç†åˆ é™¤ æå–çš„å›¾ç‰‡å­˜å‚¨
    img_store_path = getattr(config, "IMG_STORE_PATH", "extracted_images")
    if os.path.exists(img_store_path):
        try:
            shutil.rmtree(img_store_path)
            print(f"å·²åˆ é™¤æå–å›¾ç‰‡å­˜å‚¨: {img_store_path}")
        except Exception as e:
            st.error(f"æ— æ³•åˆ é™¤æå–å›¾ç‰‡å­˜å‚¨ {img_store_path}: {e}")

    # 5. ç‰©ç†åˆ é™¤ data æ–‡ä»¶å¤¹
    target = "data"
    if os.path.exists(target) and os.path.isdir(target):
        try:
            shutil.rmtree(target)
            print(f"å·²åˆ é™¤æ–‡ä»¶å¤¹: {target}")
        except Exception as e:
            st.error(f"æ— æ³•åˆ é™¤ {target}ï¼Œå¯èƒ½æ–‡ä»¶æ­£åœ¨è¢«æŸ¥çœ‹ã€‚")

    # 6. æ¸…ç† Streamlit èµ„æºç¼“å­˜
    try:
        st.cache_resource.clear()
        print("å·²æ¸…ç†èµ„æºç¼“å­˜")
    except Exception as e:
        print(f"æ¸…ç†ç¼“å­˜å¤±è´¥: {e}")

    # 7. é‡ç½® Session State
    keys_to_keep = ["has_cleared", "uploader_key"]
    for k in list(st.session_state.keys()):
        if k not in keys_to_keep:
            del st.session_state[k]

    # æ›´æ–°ä¸Šä¼ ç»„ä»¶ Key
    st.session_state["uploader_key"] += 1

    # å¼ºåˆ¶ GC
    gc.collect()
    time.sleep(1)

    return True


st.set_page_config(page_title="ä¸ªäººçŸ¥è¯†åº“åŠ©æ‰‹", layout="wide")

st.title("ğŸ¤– ä¸ªäººä¸“å±çŸ¥è¯†åº“åŠ©æ‰‹")
st.caption(f"Powered by {config.LLM_MODEL_NAME} (æ··åˆè§£æç‰ˆ)")

# --- åˆå§‹åŒ– Session State ---
if "processed_files" not in st.session_state:
    st.session_state["processed_files"] = set()

# --- ä¾§è¾¹æ ï¼šæ–‡ä»¶ä¸Šä¼ ä¸æ§åˆ¶ ---
with st.sidebar:
    st.header("1. ä¸Šä¼ æ–‡æ¡£")

    parse_mode_option = st.radio(
        "è§£æç­–ç•¥",
        ("æ··åˆæ¨¡å¼ (æ¨è)", "å¼ºåˆ¶å…¨è§†è§‰ (æœ€æ…¢)", "ä»…å¿«é€Ÿæ–‡æœ¬ (æœ€å¿«)"),
        index=0,
        help="æ··åˆæ¨¡å¼ï¼šè‡ªåŠ¨æ£€æµ‹é¡µé¢å¤æ‚åº¦ï¼Œæœ‰å›¾è¡¨æ—¶ç”¨è§†è§‰æ¨¡å‹ï¼Œçº¯æ–‡æœ¬æ—¶ç”¨å¿«é€Ÿè§£æã€‚\nå¼ºåˆ¶å…¨è§†è§‰ï¼šæ‰€æœ‰é¡µé¢éƒ½ç”¨ Qwen-VLï¼Œé€‚åˆæå¤æ‚çš„æ‰«æä»¶ã€‚"
    )

    # ç­–ç•¥æ˜ å°„
    strategy_map = {
        "æ··åˆæ¨¡å¼ (æ¨è)": "auto",
        "å¼ºåˆ¶å…¨è§†è§‰ (æœ€æ…¢)": "force",
        "ä»…å¿«é€Ÿæ–‡æœ¬ (æœ€å¿«)": "fast"
    }
    selected_strategy = strategy_map[parse_mode_option]

    uploaded_files = st.file_uploader(
        "è¯·ä¸Šä¼  PDF æ–‡æ¡£",
        type=["pdf"],
        accept_multiple_files=True,
        key=f"uploader_{st.session_state['uploader_key']}"
    )

    # æ£€æŸ¥æœ¬åœ°æ˜¯å¦æœ‰å­˜é‡æ•°æ®
    has_existing_data = os.path.exists("data") and len(os.listdir("data")) > 0 and os.path.exists(
        config.PERSIST_DIRECTORY)

    if not uploaded_files and not st.session_state.get("file_processed", False):
        if has_existing_data:
            st.info("æ£€æµ‹åˆ°ä¸Šæ¬¡è¿è¡Œçš„çŸ¥è¯†åº“ï¼Œå·²è‡ªåŠ¨åŠ è½½ã€‚")
            st.session_state["file_processed"] = True
            for f in os.listdir("data"):
                st.session_state["processed_files"].add(f)

    # å¤„ç†æ–°ä¸Šä¼ çš„æ–‡ä»¶
    if uploaded_files:
        new_files = [f for f in uploaded_files if f.name not in st.session_state["processed_files"]]

        if new_files:
            current_count = len(st.session_state["processed_files"])
            if current_count + len(new_files) > config.MAX_FILES_COUNT:
                st.error(
                    f"âŒ æ–‡ä»¶æ•°é‡è¶…è¿‡é™åˆ¶ï¼å½“å‰ {current_count}ï¼Œå°è¯•æ–°å¢ {len(new_files)}ï¼Œä¸Šé™ {config.MAX_FILES_COUNT}ã€‚")
            else:
                total_size_mb = sum([f.size for f in uploaded_files]) / (1024 * 1024)

                if total_size_mb > config.MAX_FILE_SIZE_MB:
                    st.error(f"âŒ æ€»å¤§å°è¶…è¿‡é™åˆ¶ï¼å½“å‰: {total_size_mb:.2f}MB, æœ€å¤§: {config.MAX_FILE_SIZE_MB}MB")
                else:
                    # åˆ›å»ºè¿›åº¦æ˜¾ç¤ºåŒºåŸŸ
                    progress_container = st.container()
                    with progress_container:
                        progress_bar = st.progress(0.0)
                        status_text = st.empty()
                        
                        status_text.text(f"æ­£åœ¨å‡†å¤‡å¤„ç† {len(new_files)} ä¸ªæ–°æ–‡æ¡£...")
                        
                        os.makedirs("data", exist_ok=True)

                        saved_file_paths = []
                        for file in new_files:
                            file_path = os.path.join("data", file.name)
                            with open(file_path, "wb") as f:
                                f.write(file.getbuffer())
                            saved_file_paths.append(file_path)
                        
                        # å®šä¹‰è¿›åº¦å›è°ƒå‡½æ•°
                        def progress_callback(current_page, total_pages, message):
                            """
                            è¿›åº¦å›è°ƒå‡½æ•°ï¼Œç”¨äºæ›´æ–° Streamlit è¿›åº¦æ¡
                            current_page: å½“å‰é¡µç 
                            total_pages: æ€»é¡µæ•°
                            message: çŠ¶æ€æ¶ˆæ¯
                            """
                            progress = current_page / total_pages if total_pages > 0 else 0
                            progress_bar.progress(progress)
                            status_text.text(message)
                        
                        # ä¼ é€’è¿›åº¦å›è°ƒåˆ° ingest_document
                        success = ingest_document(
                            saved_file_paths, 
                            parsing_strategy=selected_strategy,
                            progress_callback=progress_callback
                        )
                        
                        # å¤„ç†å®Œæˆï¼Œæ¸…ç†è¿›åº¦æ¡
                        progress_bar.empty()
                        status_text.empty()

                        if success:
                            st.success(f"æˆåŠŸæ·»åŠ  {len(saved_file_paths)} ä¸ªæ–°æ–‡æ¡£ï¼")
                            st.session_state["file_processed"] = True
                            for f in new_files:
                                st.session_state["processed_files"].add(f.name)

    st.divider()

    # --- AI è§’è‰²è®¾å®š ---
    st.header("2. AI è§’è‰²è®¾å®š")

    default_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŠ©æ‰‹ã€‚è¯·åŸºäºä¸‹é¢çš„ã€ä¸Šä¸‹æ–‡ã€‘å†…å®¹å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚
    å¦‚æœä¸çŸ¥é“ï¼Œè¯·ç›´æ¥æ‰¿è®¤ã€‚

    ã€ä¸Šä¸‹æ–‡ã€‘:
    {context}

    ã€ç”¨æˆ·é—®é¢˜ã€‘:
    {question}
    """
    user_prompt = st.text_area(
        "è‡ªå®šä¹‰ç³»ç»Ÿæç¤ºè¯ (Prompt)",
        value=default_prompt,
        height=200,
        help="å¿…é¡»ä¿ç•™ {context} å’Œ {question} è¿™ä¸¤ä¸ªå ä½ç¬¦ã€‚"
    )

    st.divider()

    # é‡ç½®æŒ‰é’®
    if st.button("ğŸ§¨ é‡ç½®çŸ¥è¯†åº“", type="primary"):
        reset_app()
        st.rerun()

    # é€€å‡ºæŒ‰é’®
    if st.button("ğŸ”´ é€€å‡ºç³»ç»Ÿ", key="exit_btn_sidebar"):
        st.warning("ç¨‹åºæ­£åœ¨å…³é—­...")
        time.sleep(1)
        os._exit(0)

# --- ä¸»åŒºåŸŸï¼šèŠå¤© ---
if "messages" not in st.session_state:
    st.session_state["messages"] = [{"role": "assistant", "content": "ä½ å¥½ï¼è¯·å…ˆä¸Šä¼ æ–‡æ¡£ï¼Œç„¶åé—®æˆ‘å…³äºæ–‡æ¡£çš„é—®é¢˜ã€‚"}]

for msg in st.session_state["messages"]:
    st.chat_message(msg["role"]).write(msg["content"])

if prompt := st.chat_input("è¯·è¾“å…¥ä½ çš„é—®é¢˜..."):
    st.session_state["messages"].append({"role": "user", "content": prompt})
    st.chat_message("user").write(prompt)

    if not st.session_state.get("file_processed"):
        response = "è¯·å…ˆåœ¨å·¦ä¾§ä¸Šä¼  PDF æ–‡æ¡£ï¼Œæˆ‘æ‰èƒ½å›ç­”ä½ çš„é—®é¢˜å“¦ã€‚"
        st.session_state["messages"].append({"role": "assistant", "content": response})
        st.chat_message("assistant").write(response)
    else:
        rag_chain = get_rag_chain(custom_prompt=user_prompt)
        if rag_chain:
            with st.chat_message("assistant"):
                status_placeholder = st.empty()
                status_placeholder.markdown("ğŸ” æ­£åœ¨æ£€ç´¢å¹¶æ€è€ƒ...")

                try:
                    # æ„å»ºå†å²è®°å½•
                    chat_history = []
                    for msg in st.session_state["messages"][:-1]:
                        if msg["role"] == "user":
                            chat_history.append(HumanMessage(content=msg["content"]))
                        elif msg["role"] == "assistant":
                            chat_history.append(AIMessage(content=msg["content"]))

                    # ä½¿ç”¨æµå¼ç”Ÿæˆ
                    stream_gen = rag_chain.stream({
                        "input": prompt,
                        "chat_history": chat_history
                    })
                    
                    # æå–ç¬¬ä¸€ä¸ªå…ƒç´  (metadata)
                    metadata = next(stream_gen)
                    source_docs = metadata.get("source_documents", [])
                    run_id = metadata.get("run_id", "")
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
                    if metadata.get("error"):
                        status_placeholder.empty()
                        st.warning(metadata["error"])
                        st.session_state["messages"].append({"role": "assistant", "content": metadata["error"]})
                    else:
                        # æ¸…é™¤ "æ­£åœ¨æ€è€ƒ" çŠ¶æ€
                        status_placeholder.empty()
                        
                        # æµå¼è¾“å‡ºæ–‡æœ¬
                        response_placeholder = st.empty()
                        full_response = ""
                        
                        for token in stream_gen:
                            if isinstance(token, str):
                                full_response += token
                                response_placeholder.markdown(full_response + "â–Œ")
                        
                        # ç§»é™¤å…‰æ ‡ï¼Œæ˜¾ç¤ºæœ€ç»ˆç»“æœ
                        response_placeholder.markdown(full_response)
                        st.session_state["messages"].append({"role": "assistant", "content": full_response})
                        
                        # ä¿å­˜å½“å‰ run_id ç”¨äºåé¦ˆ
                        st.session_state["last_run_id"] = run_id

                        # æ¥æºå±•ç¤º (å¸¦å¼•ç”¨ç¼–å·å¯¹åº”)
                        if source_docs:
                            with st.expander("ğŸ“š å‚è€ƒæ¥æº (ç‚¹å‡»å±•å¼€)"):
                                for i, doc in enumerate(source_docs):
                                    source = os.path.basename(doc.metadata.get("source", "æœªçŸ¥æ–‡ä»¶"))
                                    page = doc.metadata.get("page", 0) + 1
                                    mode = doc.metadata.get("parsing_mode", "unknown")
                                    st.markdown(f"**[{i + 1}] æ¥æº:** `{source}` (ç¬¬ {page} é¡µ) | æ¨¡å¼: `{mode}`")
                                    # è¿™é‡Œçš„ content æ˜¯çˆ¶å—ï¼ˆ2000å­—ï¼‰ï¼Œæˆ‘ä»¬åªå±•ç¤ºå‰ 150 å­—é¢„è§ˆ
                                    content_preview = doc.page_content[:150].replace('\n', ' ')
                                    st.caption(f"åŸæ–‡ç‰‡æ®µ: ...{content_preview}...")
                                    st.divider()
                        
                        # ç”¨æˆ·åé¦ˆæŒ‰é’®
                        st.markdown("---")
                        st.caption("è¿™ä¸ªå›ç­”å¯¹æ‚¨æœ‰å¸®åŠ©å—ï¼Ÿ")
                        col1, col2, col3 = st.columns([1, 1, 8])
                        with col1:
                            if st.button("ğŸ‘", key=f"up_{run_id}"):
                                log_feedback(run_id, 1)
                                st.toast("æ„Ÿè°¢æ‚¨çš„åé¦ˆï¼", icon="âœ…")
                        with col2:
                            if st.button("ğŸ‘", key=f"down_{run_id}"):
                                log_feedback(run_id, 0)
                                st.toast("æ„Ÿè°¢æ‚¨çš„åé¦ˆï¼æˆ‘ä»¬ä¼šç»§ç»­æ”¹è¿›ã€‚", icon="ğŸ“")

                except Exception as e:
                    status_placeholder.empty()
                    st.error(f"å‘ç”Ÿé”™è¯¯: {e}")
        else:
            st.error("çŸ¥è¯†åº“åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·é‡è¯•ã€‚")